%TODO: Papers to include:
% -  https://pubs.acs.org/doi/10.1021/jacs.4c10244
% - Sagado et al.: Automated classification of big X-ray diffraction data using deep learning models

\paragraph{ML for pXRD} Several approaches have applied machine learning methods to classification and regression tasks for powder diffractograms.

Using simulated diffractograms based on structures from the ICSD, Lee {\it et al.} trained a deep convolutional neural network (CNN) that is able to classify occurring phases in diffractograms of a specific compound pool \cite{Lee2020}. They furthermore developed models based on fully convolutional neural networks and transformer encoders that predict the crystal system and the spacegroup and other structural properties, such as the band gap \cite{Lee2022}. With their best model for the crystal system prediction on ICSD structures, they achieved a test accuracy of \SI{92.2}{\percent}.
Park {\it et al.} reached a test accuracy of roughly 81\% for a CNN, which classifies space groups of simulated single-phase diffractograms \cite{Park2017}.
A regression analysis on lattice parameters within a broader framework encompassing all material classes was conducted by Chitturi et al\cite{Chitturi2021}. They developed a distinct CNN for each crystal system, utilizing a merged dataset from both the ICSD and the Cambridge Structural Database, and managed to achieve a mean absolute percentage error of about \SI{10}{\percent} for the lattice lengths, although they encountered difficulties in accurately predicting angles.
Zhang {\it et al.} introduce a convolutional self-attention neural network trained on simulated patterns to classify crystal types \cite{zhang2024crystallographic}. Their model was tested on 23,073 unary, binary, and ternary inorganic crystal structures sourced from the COD. The study observed a noticeable performance drop when the pre-trained model was applied to real experimental patterns, as opposed to simulated data. However, their recent work \cite{cao2024simxrd} proposes using convolutional peak descriptors that consider the detector's geometry, which significantly reduces the performance gap in their benchmark tests.
The option of training purely on experimental diffractograms unfortunately is unfeasible because of the limited availability of labeled experimental diffractograms, but Salgado {\it et al.} \cite{Salgado2023} showed, that adding a fraction of experimental patterns to a simulated training dataset improves the performance on unseen experimental patterns. They used \SI{50}{\percent} of the experimental patterns contained in the RRUFF database and added those to their large simulated training set. Then they tested their model's performance on the other half of the RRUFF database and achieved a performance increase in the 230-way spacegroup classification accuracy of \num{11} percentage points compared to the same model only trained on simulated patterns.

TODO: We need a short literature review here; needs to also cover papers published after our previous paper!

TODO: briefly discuss here that there are expert models for specific classes of materials which give more information, and more generic models like ours which currently only gives you the space group and not much more; especially focus on how experimental conditions (background, noise, ... is modeled)
Phase Labeling and Lattice Refinement: https://arxiv.org/abs/2308.07897
crystal-structure phase mapping: https://www.nature.com/articles/s42256-021-00384-1


TODO: briefly discuss papers about multiphase classification and remixing of diffraction patterns
Non-negative Matrix Factorization 2018: \url{https://link.springer.com/chapter/10.1007/978-3-319-93031-2_4}
non-negative matrix factorization 2018: \url{https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2785}
Physically-informed Graph-based DRNet (PG-DRNet) 2023: \url{https://ieeexplore.ieee.org/abstract/document/10459774/}

TODO: discuss in more detail why domain randomization as we did in the last paper so far failed for background and noise, and thus why we need background and noise statistics from experiment to enhance simulated datasets and transfer them to the experimental data distribution.

The ultimate goal of ML efforts is to make PXRD data identification practical for experimental use, whether for identifying space group symmetry or phase composition. However, the current volume of experimental PXRD patterns is insufficient to effectively train ML models, highlighting an urgent need for a comprehensive experimental PXRD database. To address this, two key approaches are essential. First, developing more sophisticated simulation methods to better approximate experimental patterns\cite{cao2024simxrd}. Second, creating an experimental database that enables transfer learning to bridge the gap between simulated and real-world data. The development of opXRD is particularly significant, as it will provide a comprehensive experimental benchmark for the community, allowing fair comparison of baseline models and accurate evaluation of their applicability in real experimental situations.